## Requirements

### Python version
```bash
python --version
```
```text
Python 3.9.12
```
### Libraries used
```bash
pip3 install torch==1.13.1 pytest==7.2.1 pyyaml==6.0
```

## TODO 1 - a naive LM (`GPTVer1`)
1. **Create a naive bigram language model**
    1. Get the predictions (logit)
    2. Apply softmax on the last prediction
    3. Sample from the distribution
    4. Concat to the context
2. Files to Edit
    - gpt_v1.py
3. Test Cases
    - Get the same output as the test case
```bash
pytest tests/test_1.py -s -vv
```

---

## TODO 2 - taking the past into account  (`HeadVer1` & `GPTVer2`)

```bash
pytest tests/test_2.py -s -vv
```

---

## TODO 3 - vectorizing for loops (`HeadVer2`)

```bash
pytest tests/test_3.py -s -vv
```

---

## TODO 4 - taking the past into account with masking & normalization (`HeadVer3`)

```bash
pytest tests/test_4.py -s -vv
```

---

## TODO 5 - self-attention mechanism (`HeadVer4` & `GPTVer2`)

```bash
pytest tests/test_5.py -s -vv
```

---

## TODO 6 - positional encodings (`GPTVer3`)

```bash
pytest tests/test_6.py -s -vv
```

---

## Introduction
week2ì—ì„œëŠ” week1ì—ì„œ ì™„ì„±í•œ GPTVer3(one-head self-attention + positional encoding)ì™€ HeadVer4(self-attention head)ë¥¼ ë” ë°œì „ì‹œì¼œ ìµœì¢…ì ìœ¼ë¡œ NanoGPTë¥¼ êµ¬í˜„í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.

## TODO 7 - multi-head attention (`MultiHeadVer1`)

```shell
pytest tests/test_7.py -s -vv
```

### test_head_ver_4_and_multi_head_ver_1_are_equally_expensive & test_multi_head_helps

<img src='img/Multi-Head Attention.png' width=250>

Week1ì—ì„œ êµ¬í˜„í–ˆë˜ `HeadVer4`(self-attention head)ë¥¼ ë°”íƒ•ìœ¼ë¡œ multi-head attentionì„ êµ¬í˜„í•©ë‹ˆë‹¤.
self-attention headì—ì„œ Q, K, Vê°€ ê°ê° FC layerë¥¼ í†µê³¼í•˜ê³ ë‚˜ë©´ (batch_size, block_size, embed_size) â†’ (batch_size, block_size, head_size)ë¡œ shapeì´ ë³€ê²½ì´ ë©ë‹ˆë‹¤.
ê·¸ë¦¬ê³  embed_size = head_size * n_headsì˜ ê´€ê³„ê°€ ì„±ë¦½í•©ë‹ˆë‹¤.

> TODO 1: `MultiHeaVer1.forward`ë¥¼ êµ¬í˜„í•´ì£¼ì„¸ìš”.
> input xë¥¼ n_heads ê°œì˜ self-attention headë¥¼ í†µê³¼í•œ í›„ head_outputì„ concatnateí•©ë‹ˆë‹¤. ê·¸ë¦¬ê³  projection layer(FC)ë¥¼ í†µê³¼ì‹œì¼œ multi-head attentionì„ êµ¬í˜„í•´ì£¼ì„¸ìš”.

í…ŒìŠ¤íŠ¸ë¥¼ ëŒë ¤ë³´ê³  ë‹¤ìŒì˜ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”.
1. `MultiHeadVer1`ì™€ `HeadVer4`ì˜ ì—°ì‚°ëŸ‰ì— ì°¨ì´ê°€ ìˆë‚˜ìš”? ì—†ë‹¤ë©´ ì™œ?
2. `MultiHeadVer1`ì™€ `HeadVer4` ì¤‘ ì–´ë–¤ ê²ƒì´ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì´ë‚˜ìš”? ê·¸ ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”?

### test_multi_head_ver_2_is_faster_than_ver_1 & test_multi_head_ver_1_and_multi_head_ver_2_are_logically_equal

í…ŒìŠ¤íŠ¸ë¥¼ ëŒë ¤ë³´ê³  ë‹¤ìŒì˜ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”.
1. `MultiHeadVer2`ì™€ `MultiHeadVer1`ëŠ” ì•Œê³ ë¦¬ì¦˜ì— ì°¨ì´ëŠ” ì—†ì§€ë§Œ `MultiHeadVer2`ê°€ ì—°ì‚° ì†ë„ê°€ ë” ë¹ ë¦…ë‹ˆë‹¤. ê·¸ ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”?
---

## TODO 8 - feed forward network & residual connection (`MultiHeadVer2`)

```shell
pytest tests/test_8.py -s -vv
```

### test_ffn_helps

<img src='img/BlockVer1.png' width=250>

`BlockVer1`ì€ ìœ„ì—ì„œ êµ¬í˜„í•œ Multi-Head Attentionê³¼ FeedForwardë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.

> TODO 2-1: `FeedForward`ë¥¼ êµ¬í˜„í•´ì£¼ì„¸ìš”. $FFNN(x)=Max(0, W_1x+b_1)W_2 + b_2$  
> ($W_1$ì˜ shapeì€ (embed_size, 4 $\times$ embed_size), $W_2$ì˜ shapeì€ (4 $\times$ embed_size, embed_size) ì…ë‹ˆë‹¤.)

> TODO 2-2: `BlockVer1.forward`ì„ êµ¬í˜„í•´ì£¼ì„¸ìš”. Multi-Head Attentionì„ í†µê³¼í•œ ë’¤ FeedForward layerë¥¼ í†µê³¼ì‹œí‚¤ë©´ ë©ë‹ˆë‹¤.

í…ŒìŠ¤íŠ¸ë¥¼ ëŒë ¤ë³´ê³  ë‹¤ìŒì˜ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”.
1. `MultiHeadVer2`ì™€  `BlockVer1` ì¤‘ ì–´ë–¤ ê²ƒì´ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì´ë‚˜ìš”? ê·¸ ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”?


### test_residual_conn_helps_when_network_is_deep

<img src='img/BlockVer2.png' width=250>

`BlockVer2`ëŠ” BlockVer1ì—ì„œ Residual connectionì„ ì¶”ê°€í•œ Blockì…ë‹ˆë‹¤.

> TODO 2-3: `BlockVer2.forward`ë¥¼ êµ¬í˜„í•´ì£¼ì„¸ìš”. Multi-Head Attentionê³¼ FeedForwardì— ëŒ€í•´ ê°ê° residual Connectionì„ ì¶”ê°€í•˜ë©´ ë©ë‹ˆë‹¤.


í…ŒìŠ¤íŠ¸ë¥¼ ëŒë ¤ë³´ê³  ë‹¤ìŒì˜ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”.
1. `BlockVer1`ê³¼ `BlockVer2` ì¤‘ ì–´ë–¤ ê²ƒì´ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì´ë‚˜ìš”? ê·¸ ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”?

---

## TODO 9 - Layer Normalization (`BlockVer3`)

```shell
pytest tests/test_9.py -s -vv
```

### test_layer_norm_features_dim_is_properly_normalized & test_layer_norm_mitigates_vanishing_gradient


> TODO 3-1: `BlockVer3`ì—ì„œ ì‚¬ìš©í•  `LayerNorm`ì„ êµ¬í˜„í•´ì£¼ì„¸ìš”.

í…ŒìŠ¤íŠ¸ë¥¼ ëŒë ¤ë³´ê³  ë‹¤ìŒì˜ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”.
1. `LayerNorm`ì„ í†µê³¼í•œ í›„ì—ëŠ” ì–´ë–¤ íŠ¹ì§•ì´ ìˆë‚˜ìš”?
2. `LayerNorm`ì€ ì–´ë–»ê²Œ ê¸°ìš¸ê¸° ì†Œì‹¤ ë¬¸ì œë¥¼ ì™„í™”í•˜ë‚˜ìš”?

### test_layer_norm_helps_when_network_is_deep

<img src='img/BlockVer3.png' width=250>

> TODO 3-2: `BlockVer3.forward`ë¥¼ êµ¬í˜„í•´ì£¼ì„¸ìš”. LayerNormì„ ìœ„ì˜ ê·¸ë¦¼ì²˜ëŸ¼ Multi-Headì˜ input, FeedForwardì˜ input ì´ 2ê³³ì— ì¶”ê°€í•˜ì‹œë©´ ë©ë‹ˆë‹¤.

í…ŒìŠ¤íŠ¸ë¥¼ ëŒë ¤ë³´ê³  ë‹¤ìŒì˜ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”.
1. `BlockVer2`ì™€ `BlockVer3` ì¤‘ ì–´ë–¤ ê²ƒì´ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì´ë‚˜ìš”? ê·¸ ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”?

--- 

## TODO 10 - Dropout (`BlockVer4`)

```shell
pytest tests/test_10.py -s -vv
```
### test_block_ver_4_output_is_always_different_in_train_mode & test_block_ver_4_output_is_always_the_same_in_eval_mode

<img src='img/BlockVer4.png' width=250>

> TODO 4: `BlockVer4.forward`ë¥¼ êµ¬í˜„í•´ì£¼ì„¸ìš”. Dropout layerë¥¼ ì¶”ê°€í•˜ë©´ë©ë‹ˆë‹¤. Dropoutì€ Multi-Headì˜ output, FeedForwardì˜ output ì´ 2ê³³ì— ì¶”ê°€í•˜ì‹œë©´ ë©ë‹ˆë‹¤.

í…ŒìŠ¤íŠ¸ë¥¼ ëŒë ¤ë³´ê³  ë‹¤ìŒì˜ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”.
1. ì™œ í•™ìŠµ ëª¨ë“œ ì¼ ë•Œ `BlockVer4`ì˜ ì¶œë ¥ì€ í•­ìƒ ë‹¤ë¥¼ê¹Œìš”?
2. ì™œ í‰ê°€ ëª¨ë“œ ì¼ ë•Œ `BlockVer4`ì˜ ì¶œë ¥ì€ í•­ìƒ ê°™ì„ê¹Œìš”?

### test_dropout_helps

í…ŒìŠ¤íŠ¸ë¥¼ ëŒë ¤ë³´ê³  ë‹¤ìŒì˜ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”.
1. `BlockVer3`ì™€ `BlockVer4` ì¤‘ ì–´ë–¤ ê²ƒì´ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì´ë‚˜ìš”? ê·¸ ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”?


<br>

## Introduction
<img src='img/week1.png' width=300>

Onboarding Course week1ì—ì„œëŠ” character leve tokenizerë¥¼ ì‚¬ìš©í•˜ëŠ” Simplest BigramLanguageModelì„ ë°œì „ì‹œì¼œë³´ê³  í•©ë‹ˆë‹¤.

DataëŠ” Shakespeareì˜ í¬ê³¡ ëŒ€ë³¸ì„ input.txtë¡œ ì œê³µí•´ë“œë ¸ì§€ë§Œ, ì›í•˜ëŠ” textë¥¼ ì‚¬ìš©í•˜ì…”ë„ ë¬´ê´€í•©ë‹ˆë‹¤.

week1ì˜ ìµœì¢… ëª©í‘œëŠ” one-head self-attention(HeadVer4)ë¥¼ ì ìš©í•œ GPTVer3ë¥¼ êµ¬í˜„í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

## Tokenization
ìì—°ì–´ì²˜ë¦¬ë¥¼ ìœ„í•´ì„  ë§ë­‰ì¹˜ë¥¼ ì ì ˆíˆ ì „ì²˜ë¦¬ í•´ì•¼í•©ë‹ˆë‹¤. 

Tokenizationì€ ì „ì²˜ë¦¬ ê³¼ì •ì˜ ì‹œì‘ìœ¼ë¡œ, ë§ë­‰ì¹˜ë¥¼ tokenì´ë¼ëŠ” ë‹¨ìœ„ë¡œ ë‚˜ëˆ ì£¼ëŠ” ì‘ì—…ì„ ë§í•©ë‹ˆë‹¤. ê·¸ëŸ°ë° í† í°í™”ë¥¼í•˜ë‹¤ë³´ë©´ ì—¬ëŸ¬ ì„ íƒì˜ ìˆœê°„ì´ ë°œìƒí•©ë‹ˆë‹¤. ê°€ë ¹ *I donâ€™t like olive* ë¼ëŠ” ë¬¸ì¥ì´ ì¡´ì¬í•  ë•Œ *donâ€™t*ë¥¼ í† í°í™”í•˜ëŠ” ë°©ë²•ì€ ë‹¤ì–‘í•©ë‹ˆë‹¤. 

- don / t
- dont
- do  / nâ€™t

trainí•  ì „ì²´ textë¥¼ tokenizationí•˜ë©´ ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ vocabularyë¥¼ ë§Œë“¤ì–´ tokenì„ ì •ìˆ˜ë¡œ ì¸ì½”ë”©ì„ í•©ë‹ˆë‹¤. ê·¸ëŸ°ë° inferenceë¥¼ í•˜ëŠ” ê³¼ì •ì—ì„œ ê°€ë ¹ ì˜¤íƒ€ì™€ ê°™ì´ vocabularyì— ì—†ëŠ” ë‹¨ì–´(train ë‹¨ê³„ì—ì„œ ì ‘í•˜ì§€ ëª»í•œ ë‹¨ì–´)ê°€ ì¡´ì¬í•˜ëŠ” ê²½ìš° OOV(Out-Of-Vocabulary) ë¬¸ì œê°€ ë°œìƒí•˜ê²Œ ë©ë‹ˆë‹¤.

ìœ„ì™€ ê°™ì€ ë¬¸ì œë“¤ì„ í•´ê²°í•˜ê¸° ìœ„í•´ ë‹¤ì–‘í•œ tokenization ì „ëµì´ ì—°êµ¬ë˜ì—ˆê³ , ê·¸ì¤‘ BPE(Byte Pair Encoding)ë¥¼ main_bpe.pyì— ê°„ë‹¨íˆ êµ¬í˜„í•´ë´¤ìŠµë‹ˆë‹¤. BPEë¡œ vocabularyë¥¼ êµ¬ì„±í•˜ë©´ ìœ„ì™€ ê°™ì´ ì´ˆë°˜ì—ëŠ” vocabulary sizeê°€ ì¦ê°€í•˜ë‹¤ê°€ ì ì  ê°ì†Œí•˜ëŠ” ê²½í–¥ì„ ë³´ì…ë‹ˆë‹¤.

<img src='img/BPE.png' width=300>

```text
ğŸ’¡ ë³¸ ì½”ìŠ¤ì—ì„  Character level tokenizerë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
```

## GPTVer1
`GPTVer1`ì€ `context`ê°€ ì£¼ì–´ì§€ê³  ë‹¤ìŒ tokenì„ ì˜ˆì¸¡ í•  ë•Œ ì˜¤ì§ ì§ì „ tokenë§Œì„ ì°¸ê³ í•˜ëŠ” BigramLMì…ë‹ˆë‹¤. 

$$
P(w|like) =  {count(like , w)\over count(like)}
$$

ê°€ë ¹ `context` ì—ì„œ likeê°€ 10ë²ˆ ë“±ì¥í–ˆê³ , like appleì´ 8ë²ˆ like orangeê°€ 2ë²ˆ ë“±ì¥í–ˆë‹¤ë©´ $P(apple|like)$ ëŠ” 0.8,  $P(orange|like)$ ëŠ” 0.2ê°€ ë©ë‹ˆë‹¤. BigramLMì€ ì´ì²˜ëŸ¼ ë§ˆì§€ë§‰ tokenì— ëŒ€í•´ ë‹¤ìŒì— ì˜¬ tokenì— ëŒ€í•œ í™•ë¥ ì„ ë°”íƒ•ìœ¼ë¡œ í•˜ëŠ” LMì…ë‹ˆë‹¤.

`GPTVer1` ì—ì„  (`vocab_size` x `vocab_size`)ì˜ `token_embedding_table`ì„ ë§Œë“¤ê³  ì´ë¥¼ í•™ìŠµí•©ë‹ˆë‹¤. ê° tokenì˜ ì •ìˆ˜ ì¸ì½”ë”© ê°’ì€ tableì˜ indexì— ëŒ€ì‘í•˜ê³ , `token_embedding_table(index)`ëŠ” ë‹¤ìŒì— ë‚˜ì˜¬ í† í°ì— ëŒ€í•œ ë¡œì§“ê°’ì´ ë©ë‹ˆë‹¤.

Language Modelë¡œ textë¥¼ `generate`í•  ë•Œ classificationì²˜ëŸ¼ max probabilityë¥¼ ì„ íƒí•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ í™•ë¥ ë¶„í¬ì—ì„œ ë‹¤ìŒ í† í°ì„ ì„ì˜ì¶”ì¶œí•©ë‹ˆë‹¤. 

GPTVer1ì—ì„œëŠ” generate í•¨ìˆ˜ë¥¼ êµ¬í˜„í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.

```bash
# hint
idx_next = torch.multinomial(probs, num_samples=1)
```

## HeadVer1 & GPTVer2

`GPTVer1` ì€ ì§ì „ tokenì˜ ì •ë³´ë§Œì„ í† ëŒ€ë¡œ ë‹¤ìŒ tokenì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤. í•˜ì§€ë§Œ, ì´ ê²½ìš° ì• ë¶€ë¶„ê³¼ ë’· ë¶€ë¶„ì˜ ë¬¸ë§¥ì´ ì „í˜€ ì—°ê²°ë˜ì§€ ì•ŠëŠ” ê²½ìš°ë„ ìƒê¸¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

`GPTVer2`ì™€ `HeadVer1`ì—ì„œëŠ” ì§ì „ tokenê³¼ í•¨ê»˜ ì´ì „ tokenë“¤ì˜ embedding vectorì˜ í‰ê· ìœ¼ë¡œ ë‹¤ìŒ tokenì„ ì˜ˆì¸¡í•˜ê³ ì í•©ë‹ˆë‹¤. ê°€ë ¹ 4th tokenì„ ì˜ˆì¸¡í•˜ê³ ì í•˜ë©´ 1st, 2nd, 3rd tokenì˜ embedding vectorì˜ í‰ê· ìœ¼ë¡œ ë‹¤ìŒ tokenì„ ì˜ˆì¸¡í•˜ê³ ì í•©ë‹ˆë‹¤.

HeadVer1ì—ì„œëŠ” ì´ë¥¼ **2ì¤‘ forë¬¸ì„ ì‚¬ìš©í•˜ì—¬ êµ¬í˜„í•´ì£¼ì„¸ìš”**

`hint: Each example across batch dimension is of course processed completely independently and never "talk" to each other`

GPTVer2ì—ì„œëŠ” embedding tableì´ (`vocab_size` x `embed_size`)ë¡œ ë³€ê²½ëìŠµë‹ˆë‹¤. ìµœì¢… ë‹¨ê³„ì—ì„œ fully connected layer(self.lm_head)ë¥¼ ì‚¬ìš©í•˜ì—¬ logitsì„ (`batch_size`, `block_size`, `vocab_size`)ë¡œ ë§Œë“¤ì–´ì£¼ì„¸ìš”.

`hint: embedding table â†’ Head â†’ FC`

## HeadVer2
HeadVer2ì—ì„œëŠ” HeadVer1ì„ **matrix multiplicationì„ ì‚¬ìš©í•˜ì—¬ êµ¬í˜„í•´ì£¼ì„¸ìš”**

`hint: torch.tril(...)`

## HeadVer3
HeadVer3ì—ì„œëŠ” HeadVer2ë¥¼ **softmaxë¥¼ ì‚¬ìš©í•˜ì—¬ êµ¬í˜„í•´ì£¼ì„¸ìš”**

`hint: softmax([0, 0, -inf, -inf]) = [0.5, 0.5, 0, 0]`

## HeadVer4 (Self-attention Head)
HeadVer4ì—ì„œëŠ” **self-attention headë¥¼ êµ¬í˜„í•´ë³´ê³ ì í•©ë‹ˆë‹¤. softmaxë¥¼ ì ìš©í•  ë•Œ HeadVer3ì˜ ì „ëµì„ ì‚¬ìš©í•˜ì—¬ êµ¬í˜„í•´ì£¼ì„¸ìš”.**

$$
Attention(Q, K, V) = softmax({QK^T \over \sqrt d_k})V
$$

TODO ìœ„ì˜ if debug: ëŠ” test codeë¥¼ ìœ„í•œ ë¶€ë¶„ì´ë‹ˆ, ì´ ë¶€ë¶„ì€ ìˆ˜ì •í•˜ì§€ ë§ì•„ì£¼ì„¸ìš”.

HeadVer4ì—ì„œëŠ” scailingì„ ì˜ í–ˆëŠ”ì§€ì™€ softmaxë¥¼ ì˜ ì ìš©í–ˆëŠ”ì§€ì— ëŒ€í•´ testë¥¼ í•©ë‹ˆë‹¤. ì´ë•Œ test code ì ìš©ì— í•„ìš”í•œ parameterë¥¼ ì €ì¥í•´ì£¼ì…”ì•¼í•©ë‹ˆë‹¤. ì•„ë˜ëŠ” pseudo codeì´ê³  ê° ì—°ì‚°ì„ ë§ˆë¬´ë¦¬í•˜ê³  í•´ë‹¹ ë³€ìˆ˜ì— ì €ì¥í•˜ì‹œë©´ ë©ë‹ˆë‹¤.

1. self.var = (Q@K^T / sqrt(d_k)).var() â† scailing ì´í›„ varianceë¥¼ ì €ì¥í•˜ì‹œë©´ ë©ë‹ˆë‹¤.
2. self.wei = Attention(Q, K, V) â† ìµœì¢… weië¥¼ ì €ì¥í•˜ì‹œë©´ ë©ë‹ˆë‹¤.

`hint: "Scaled" attention additional dividesÂ weiÂ by 1/sqrt(head_size). This makes it so when input Q,K are unit variance, wei will be unit variance too and Softmax will stay diffuse and not saturate too much.`

## GPTVer3
ì™„ì„±í•œ HeadVer4ë¥¼ ì‚¬ìš©í•˜ì—¬ GPTVer3 êµ¬í˜„í•˜ê³ ì í•©ë‹ˆë‹¤.

ìœ„ì—ì„œ êµ¬í˜„í•œ HeadVer4ëŠ” ê³¼ê±°ì˜ ì •ë³´ë¥¼ ë°˜ì˜ì„ í•˜ì§€ë§Œ, RNNê³¼ ë‹¬ë¦¬ Sequential dataë¥¼ ë°˜ì˜í•˜ì§€ ëª»í•©ë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ **Positional encodingê³¼ ìµœì¢… logitsì„ êµ¬í˜„í•´ë´…ë‹ˆë‹¤.**

GPTVer3ì—ì„œë„ embedding tableì˜ shapeì´ (`vocab_size` x `embed_size`) ì…ë‹ˆë‹¤. ìµœì¢… ë‹¨ê³„ì—ì„œ fully connected layer(self.lm_head)ë¥¼ ì‚¬ìš©í•˜ì—¬ logitsì„ (`batch_size`, `block_size`, `vocab_size`)ë¡œ ë§Œë“¤ì–´ì£¼ì„¸ìš”.

### Positional encoding

[https://towardsdatascience.com/master-positional-encoding-part-i-63c05d90a0c3](https://towardsdatascience.com/master-positional-encoding-part-i-63c05d90a0c3)

[https://www.notion.so/WEEK9-How-does-Positional-Encoding-work-0d0e5b9d17464af08f39b4977c073beb#f77f059d74ae45599eca16c1b3924e91](https://www.notion.so/0d0e5b9d17464af08f39b4977c073beb)

### Logits
```bash
# pseudo code
x = tok_emb + pos_emb
x = head(x)
logits = FC(x)
```
